{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd96dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import webbrowser\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "from nltk.corpus import stopwords\n",
    "from wand.image import Image as WImage\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33afc1c0",
   "metadata": {},
   "source": [
    "#### From pdf to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed40e3a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PdfConverter:\n",
    "\n",
    "   def __init__(self, file_path):\n",
    "       self.file_path = file_path\n",
    "        \n",
    "# → Function used to convert pdf to text to allow the post-processing.\n",
    "   def convert_pdf_to_txt(self):\n",
    "       rsrcmgr = PDFResourceManager()\n",
    "       retstr = StringIO()\n",
    "       codec = 'utf-8'  # 'utf16','utf-8'\n",
    "       laparams = LAParams()\n",
    "       device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "       fp = open(self.file_path, 'rb')\n",
    "       interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "# → Proposing just to read the first page of the pdf, because this is normally where the abstract and the introduction are.\n",
    "       maxpages = 0\n",
    "        \n",
    "       caching = True\n",
    "       pagenos = set()\n",
    "       for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, caching=caching, check_extractable=True):\n",
    "           interpreter.process_page(page)\n",
    "       fp.close()\n",
    "       device.close()\n",
    "       str = retstr.getvalue()\n",
    "       retstr.close()\n",
    "       return str\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # → Put the path of your pfd here :\n",
    "    file_path='sample-papers/11.pdf'\n",
    "    pdfConverter = PdfConverter(file_path)\n",
    "    with WImage(filename=file_path+\"[0]\") as img: img.save(filename=\"cover.png\")\n",
    "    \n",
    "    # → Now we have the pdf in plain text format. I am also applying a lower() here to avoid dealing with this later.\n",
    "    text = pdfConverter.convert_pdf_to_txt().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08777388",
   "metadata": {},
   "source": [
    "#### Post-processing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e261a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# → First post-processing for the text : Deleting all the symbols. [^\\w] will match anything that's not alphanumeric or underscore.\n",
    "text = re.sub(r'[^\\w]', ' ', text)\n",
    "\n",
    "# → Second post-processing for the text. Avoiding stop words using the nltk dictionary.\n",
    "generalDictionary = stopwords.words('english')\n",
    "wordsArray = text.split()\n",
    "generalResult = [word for word in wordsArray if word.lower() not in generalDictionary]\n",
    "text = ' '.join(generalResult)\n",
    "\n",
    "# → Third post-processing for the text. Avoiding numbers.\n",
    "notNumbers = re.findall(r'[a-zA-Z]\\w+',text)\n",
    "text = ' '.join(notNumbers)\n",
    "\n",
    "# → Printing the number of words in the text after the whole post-processing.\n",
    "print(len(notNumbers))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e33e1",
   "metadata": {},
   "source": [
    "#### Getting the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5a129ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords:\n",
      "\n",
      "1 eye\n",
      "2 flight\n",
      "3 approach\n",
      "4 position\n",
      "5 angle\n",
      "6 altitude\n",
      "7 point\n",
      "8 trials\n",
      "9 landing\n",
      "10 airplane\n"
     ]
    }
   ],
   "source": [
    "# → Calculating the repetition frequency of each word.\n",
    "def word_count(str):\n",
    "    counts = dict()\n",
    "    words = str.split()\n",
    "    \n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "# → dictionary that contains the repetition frecuency of a word and its value.\n",
    "d = word_count(text)\n",
    "\n",
    "# → Simple array and counter to select the desired number of keywords that we want.\n",
    "array = []\n",
    "i = 0\n",
    "\n",
    "for w in sorted(d, key=d.get, reverse=True):\n",
    "    array.append(w)\n",
    "    # → Uncomment the following to the see the complete dictionary and its values.\n",
    "    #print(w, d[w])\n",
    "\n",
    "desiredKeywords = 10\n",
    "\n",
    "print ('Keywords:\\n')\n",
    "for i in range(desiredKeywords):\n",
    "    print (str(i+1)+' '+array[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca41652",
   "metadata": {},
   "source": [
    "#### You can display the pdf cover to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='cover.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
